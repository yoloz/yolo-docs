:::info
什么是 S3？
英文全称：Amazon Simple Storage Service(亚马逊简单存储服务)

我们可以看出 S3 是 Amazon 公司的产品，亚马逊网络服务 (AWS) 已成为公共云计算中的主导服务，Amazon 在 2006 年首次提供 S3，如今，该系统存储了数十万亿个对象，单个对象的大小范围可以从几千字节到 5TB，并且对象被排列成称为“桶”的集合。
:::

## S3 协议

多年来，Amazon S3 接口已经发展成为一个非常强大的数据管理接口，与传统的文件系统接口不同，它为应用程序开发人员提供了一种通过丰富的 API 集控制数据的方法。

这些方法慢慢的发展成了 S3 协议，在国内外很多云存储厂商都是基于 S3 协议，并且都支持通用的 S3 接口，比如国内著名的阿里云的 oss、腾讯云的 cos、华为云的 obs 等等。

## S3 API

S3 API 是一个应用程序编程接口，常用的 API 就是读、写、增、删、改、查等等。使用标准的 SOAP 和 REST 定义。

还有其他功能，比如：元数据、多租户、安全和策略、生命周期管理、原子更新、搜索、日志记录、通知、复制、加密、计费等。

:::info
对于对象的获取，除了用 http 直接按照 C/S 方式获取之外，亚马逊支持 BT 协议，也就是说提供种子。
:::

## S3 SDK

各种语言的 SDK(略)

## S3 基本概念

### Bucket

类比于文件系统的目录，不能嵌套，也就是不能有子 bucket，官方的说法是起到 namespace 的作用，是访问控制的基本单位。不过可以用 Object 来模拟多级目录这种。

### Object

类比文件系统的文件,对象中带有对象名名，对象属性，Versioning 属性(早期的 S3 资料中没有这一概念，应该是演进的结果，其面对的是有版本控制的需求的用户)等。

### Keys

类比文件名，key 的样式也是 URL。
:::note
亚马逊的服务都是使用 Web Service 或 REST 方式访问的。例如:http://doc.s3.amazonaws.com/2006-03-01/AmazonS3.wsdl,其中‘doc’就是目录名（bucket），”2006-03-01/AmazonS3.wsdl”是文件名（对象名）。如果引入了version则bucket + key + version 唯一标示一个版本的文件
:::

### Versioning

类比 CVS 中的一个版本，这个是文件系统不具备的。同名文件的写入并不覆盖已有文件而是增加了一个最新的文件版本。同样删除也不是真正删除，而是 mark 了删除标记。

### Regions

文件存储的地理位置，这个也是文件系统中不存在的，就是不同的地理区域，用户可以指定将文件存在某个国家的服务器。

## 工作原理

Amazon Simple Storage Service (Amazon S3) 是一种对象存储服务，提供行业领先的可扩展性、数据可用性、安全性和性能。各种规模和行业的客户可以为几乎任何使用案例存储和保护任意数量的数据，例如数据湖、云原生应用程序和移动应用程序。借助高成本效益的存储类和易于使用的管理功能，您可以优化成本、组织数据并配置精细调整过的访问控制，从而满足特定的业务、组织和合规性要求。

![s3工作原理](/docs/concept/s3.png)

此示意图显示了如何将数据移动到 Amazon S3，管理存储在 Amazon S3 中的数据，以及利用其他服务分析数据。三个部分从左至右依次显示。

第一部分是一个数据库、一个服务器和一个文档的示意图。第一部分的标题为“移动数据”。 第一部分的正文为：“将数据从任何位置移动到 Amazon S3 – 无论是在云端、应用程序中，还是在本地”。 附近的图标显示了不同类型的数据：“分析数据”、“日志文件”、“应用程序数据”、“视频和图片”以及“备份和归档”。

第二部分是一个空桶的示意图。第二部分的标题为“Amazon S3”。 第二部分的正文为：“为了从任意位置存储和检索任意数量的数据而构建的对象存储”。

第二部分的“存储数据”标题下还有更多内容。 具体内容为：“创建存储桶，指定区域、访问控制和管理选项。上传任意数量的数据”。 附近的示意图显示了一个包含一个方块、一个圆形和一个三角形的桶。
第二部分还包含显示不同 Amazon S3 功能的图标。此处显示的功能有：“控制数据访问权限”、“利用存储类优化成本”、“将数据复制到任意区域”、“从本地或 VPC 访问”、“保护数据安全”和“随时掌握您的存储”。

第三部分的标题为“分析数据”。 第三部分的正文为：“使用 AWS 和第三方服务分析数据，以获取见解”。 附近的图标显示了不同的数据分析方式：“人工智能（AI）”、“高级分析”和“机器学习（ML）”。

## 对象存储与 HDFS

[三个理由告诉你对象存储替换 HDFS 还不错](https://www.cnblogs.com/nucdy/p/6274022.html)

### HDFS 的标准三副本配置容量更大

对象存储可提供更好的数据保护 虽然 HDFS 能够利用内部的服务器级存储，它实际上是按照其标准的数据保护策略将所有数据做了三个副本。因此，尽管可以使用较便宜的服务器内部的硬盘驱动器，它可能并不像最初希望的那样经济，因为容量需求要乘以 3。

使用基于对象的存储系统，提供亚马逊简单存储服务（S3）协议访问，这是 Hadoop 除了 HDFS 也同样支持的。这些系统可以是纯软件，因此可以使用商用服务器和服务器级存储。但不同于默认的 HDFS，许多对象存储系统都提供纠删编码。这种数据保护机制类似于 RAID 但粒度更细，可以在对象或子对象的层面操作，把数据和奇偶校验位分布到存储集群的各个节点上。其结果是，可以达到相似或更高水平的数据冗余性，而只需大约 25％至 30％的额外开销。相比之下， HDFS 的标准三副本配置下的额外容量开销为 200％。

### HDFS 主节点的高可用性需要额外措施

HDFS 具有一个主节点和一系列从节点。从节点处理数据并将结果发送给主节点。主节点还需要维护数据复制策略以及基本的集群管理。如果主节点发生故障，集群的其余节点将不能被访问。 HDFS 对主节点只提供了有限的保护，所以企业需要采取特殊措施来实现主节点的高可用性。

如上所述，在对象存储系统中，主节点与从节点都能受到相同的纠删编码的数据保护。此外，由主节点维护的管理 Hadoop 集群所需的所有元数据(metadata)都可以存储在集中化的对象存储系统中。这样当主节点发生故障时，从节点或备用节点可以迅速变成为主节点。

### HDFS 不能进行单独扩展计算或存储

像任何其他架构一样，Hadoop 对计算和存储容量也会有不同程度的需求。问题是，HDFS 要求计算能力和存储容量需要按比例进行扩展，这意味着你不能单独对某一种资源进行扩充。

要说明这一点最常见的方式是当一个 Hadoop 架构的存储容量用尽时，因为增加更多容量就意味着加入另一个装满硬盘的节点，这也增加了更多的计算能力。反之亦如此，作为 Hadoop 基础设施，往往需要更多的处理能力，但存储空间却很充裕。大多数时候，当购置了一个新的服务器以增加计算能力时，它也带来了新的存储空间。其结果是，Hadoop 架构总是在某种资源上浪费金钱，而对另一种资源却总是缺乏。

对象存储允许容量和计算能力各自独立地进行扩展。计算节点可以是 1U 或 2U 的机箱，通过固态存储引导。对象存储系统可以装满高容量驱动器，从而保持每 GB 成本最低。更重要的是，随着应用环境的变化，每一层都可以独立扩展。

HDFS 之于 Hadoop 的主要优点是低成本和高性能，这得益于数据存放于本地。而利用商业存储硬件的对象存储系统同样可以提供类似的低成本，尤其是当采用纠删编码来提高数据保护效率时更是如此。10 GbE 的高速网络现在已经很实惠，这些都使 HDFS 将数据和计算放在一起所带来的性能优势不复存在。对象存储提供了一种更具成本效益，更可靠，而且性能至少跟 HDFS 相当的基础架构，它理所当然应该成为一种可行的 HDFS 替代解决方案。
