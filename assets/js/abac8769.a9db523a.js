"use strict";(self.webpackChunkyolo_docs=self.webpackChunkyolo_docs||[]).push([[187],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>f});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},u=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),p=c(n),m=i,f=p["".concat(l,".").concat(m)]||p[m]||d[m]||r;return n?a.createElement(f,o(o({ref:t},u),{},{components:n})):a.createElement(f,o({ref:t},u))}));function f(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[p]="string"==typeof e?e:i,o[1]=s;for(var c=2;c<r;c++)o[c]=n[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},511:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var a=n(7462),i=(n(7294),n(3905));const r={},o=void 0,s={unversionedId:"bigdata/kafka\u6d88\u8d39\u8005\u6e90\u7801",id:"bigdata/kafka\u6d88\u8d39\u8005\u6e90\u7801",title:"kafka\u6d88\u8d39\u8005\u6e90\u7801",description:"\u5982\u4e0b\u662f kafka \u6d88\u8d39\u8005 java api \u7684\u8ba2\u9605(subscribe)\u6d41\u7a0b(v0.10)",source:"@site/docs/bigdata/kafka\u6d88\u8d39\u8005\u6e90\u7801.md",sourceDirName:"bigdata",slug:"/bigdata/kafka\u6d88\u8d39\u8005\u6e90\u7801",permalink:"/docs/bigdata/kafka\u6d88\u8d39\u8005\u6e90\u7801",draft:!1,editUrl:"https://github.com/yoloz/yolo-docs/tree/docusaurus/docs/bigdata/kafka\u6d88\u8d39\u8005\u6e90\u7801.md",tags:[],version:"current",lastUpdatedAt:1688721415,formattedLastUpdatedAt:"2023\u5e747\u67087\u65e5",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"kafka\u5b89\u5168\u914d\u7f6e",permalink:"/docs/bigdata/kafka\u5b89\u5168\u914d\u7f6e"},next:{title:"kerberos\u4e86\u89e3",permalink:"/docs/bigdata/kerberos\u4e86\u89e3"}},l={},c=[{value:"initialize",id:"initialize",level:2},{value:"ClusterResourceListener",id:"clusterresourcelistener",level:3},{value:"Metadata",id:"metadata",level:3},{value:"ChannelBuilder",id:"channelbuilder",level:3},{value:"NetworkClient",id:"networkclient",level:3},{value:"ConsumerNetworkClient",id:"consumernetworkclient",level:3},{value:"OffsetResetStrategy",id:"offsetresetstrategy",level:3},{value:"PartitionAssignor",id:"partitionassignor",level:3},{value:"ConsumerCoordinator",id:"consumercoordinator",level:3},{value:"Fetcher",id:"fetcher",level:3},{value:"subscribe",id:"subscribe",level:2},{value:"consumer poll",id:"consumer-poll",level:2},{value:"acquire()",id:"acquire",level:3},{value:"pollOnce",id:"pollonce",level:3},{value:"client.maybeTriggerWakeup()",id:"clientmaybetriggerwakeup",level:3},{value:"coordinator.poll",id:"coordinatorpoll",level:3},{value:"invokeCompletedOffsetCommitCallbacks",id:"invokecompletedoffsetcommitcallbacks",level:3}],u={toc:c},p="wrapper";function d(e){let{components:t,...n}=e;return(0,i.kt)(p,(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"\u5982\u4e0b\u662f kafka \u6d88\u8d39\u8005 java api \u7684\u8ba2\u9605(subscribe)\u6d41\u7a0b(v0.10)"),(0,i.kt)("h2",{id:"initialize"},"initialize"),(0,i.kt)("p",null,"\u5b9e\u73b0\u7c7b org.apache.kafka.clients.consumer. KafkaConsumer.java"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},'private KafkaConsumer(ConsumerConfig config,\n                      Deserializer<K> keyDeserializer,\n                      Deserializer<V> valueDeserializer) {\n    try {......} catch (Throwable t) {\n        // call close methods if internal objects are already constructed\n        // this is to prevent resource leak. see KAFKA-2121\n        close(0, true);\n        // now propagate the exception\n        throw new KafkaException("Failed to construct kafka consumer", t);\n    }\n}\n')),(0,i.kt)("p",null,"try \u5757\u4e2d\uff0c\u4e00\u4e9b\u76f8\u5173\u53c2\u6570\u7684\u5904\u7406(\u7565)\uff0c\u5176\u6b21\u4e00\u4e9b\u5bf9\u8c61\u7684\u521d\u59cb\u5316\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"ClusterResourceListeners clusterResourceListeners = configureClusterResourceListeners(keyDeserializer, valueDeserializer, reporters, interceptorList);\nthis.metadata = new Metadata(retryBackoffMs, config.getLong(ConsumerConfig.METADATA_MAX_AGE_CONFIG), false, clusterResourceListeners);\nList<InetSocketAddress> addresses = ClientUtils.parseAndValidateAddresses(config.getList(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG));\nthis.metadata.update(Cluster.bootstrap(addresses), Collections.<String>emptySet(), 0);\n")),(0,i.kt)("h3",{id:"clusterresourcelistener"},"ClusterResourceListener"),(0,i.kt)("p",null,"A callback interface that users can implement when they wish to get notified about changes in the Cluster metadata. Users who need access to cluster metadata in interceptors, metric reporters, serializers and deserializers can implement this interface.\n\u56de\u8c03\u63a5\u53e3\uff0c\u83b7\u53d6\u96c6\u7fa4\u76f8\u5173\u4fe1\u606f\u7684\u53d8\u52a8\u3002"),(0,i.kt)("h3",{id:"metadata"},"Metadata"),(0,i.kt)("p",null,"A class encapsulating some of the logic around metadata.\nThis class is shared by the client thread (for partitioning) and the background sender thread.\nMetadata is maintained for only a subset of topics, which can be added to over time. When we request metadata for a topic we don't have any metadata for it will trigger a metadata update.\nIf topic expiry is enabled for the metadata, any topic that has not been used within the expiry interval is removed from the metadata refresh set after an update. Consumers disable topic expiry since they explicitly manage topics while producers rely on topic expiry to limit the refresh set.",(0,i.kt)("br",{parentName:"p"}),"\n","\u5143\u6570\u636e\u7c7b\u3002",(0,i.kt)("br",{parentName:"p"}),"\n","\u5ba2\u6237\u7aef\u7ebf\u7a0b(for partitioning)\u548c\u540e\u53f0\u53d1\u9001\u7ebf\u7a0b\u5171\u4eab\u5143\u6570\u636e\u3002",(0,i.kt)("br",{parentName:"p"}),"\n","\u5143\u6570\u636e\u4ec5\u7ef4\u62a4\u4e3b\u9898\u7684\u4e00\u5c0f\u90e8\u5206\uff0c\u968f\u65f6\u95f4\u589e\u52a0\uff0c\u5f53\u5411\u4e3b\u9898\u8bf7\u6c42\u5143\u6570\u636e\u65f6\uff0c\u5982\u679c\u6ca1\u6709\u5143\u6570\u636e\uff0c\u5219\u89e6\u53d1\u5143\u6570\u636e\u66f4\u65b0\u3002",(0,i.kt)("br",{parentName:"p"}),"\n","\u5982\u679c\u5143\u6570\u636e\u542f\u7528\u4e86\u5230\u671f\u529f\u80fd\uff0c\u5728\u66f4\u65b0\u64cd\u4f5c\u4e2d\u5c06\u4ece\u5143\u6570\u636e\u96c6\u4e2d\u5220\u9664\u8fc7\u671f\u7684\u4e3b\u9898\u3002\u6d88\u8d39\u8005\u7981\u7528\u4e3b\u9898\u5230\u671f\uff0c\u56e0\u4e3a\u5b83\u4eec\u660e\u786e\u5730\u7ba1\u7406\u4e3b\u9898\uff0c\u800c\u751f\u4ea7\u8005\u4f9d\u9760\u4e3b\u9898\u5230\u671f\u6765\u9650\u5236\u5237\u65b0\u96c6\u5927\u5c0f\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"ChannelBuilder channelBuilder = ClientUtils.createChannelBuilder(config);\nNetworkClient netClient = new NetworkClient(\n        new Selector(config.getLong(ConsumerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG), metrics, time, metricGrpPrefix, channelBuilder),\n        this.metadata,\n       ................);\nthis.client = new ConsumerNetworkClient(netClient, metadata, time, retryBackoffMs,\n        config.getInt(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG));\n")),(0,i.kt)("h3",{id:"channelbuilder"},"ChannelBuilder"),(0,i.kt)("p",null,"A ChannelBuilder interface to build Channel based on configs."),(0,i.kt)("h3",{id:"networkclient"},"NetworkClient"),(0,i.kt)("p",null,"A network client for asynchronous request/response network i/o. This is an internal class used to implement the user-facing producer and consumer clients.",(0,i.kt)("br",{parentName:"p"}),"\n","This class is not thread-safe!",(0,i.kt)("br",{parentName:"p"}),"\n","\u9762\u5411\u751f\u4ea7\u8005\u6d88\u8d39\u8005\u5ba2\u6237\u7aef\u7684\u7f51\u7edc\u5185\u90e8\u7c7b\uff0c\u5f02\u6b65\u7f51\u7edc IO\uff0c\u975e\u7ebf\u7a0b\u5b89\u5168\u3002"),(0,i.kt)("h3",{id:"consumernetworkclient"},"ConsumerNetworkClient"),(0,i.kt)("p",null,"Higher level consumer access to the network layer with basic support for request futures. This class is thread-safe, but provides no synchronization for response callbacks. This guarantees that no locks are held when they are invoked.",(0,i.kt)("br",{parentName:"p"}),"\n","\u652f\u6301\u57fa\u672c reuqest future \u7684\u7f51\u7edc\u5c42\uff0c\u7ebf\u7a0b\u5b89\u5168\uff0c\u4f46\u4e0d\u63d0\u4f9b\u54cd\u5e94\u56de\u8c03\u7684\u540c\u6b65\u3002\u53ef\u4ee5\u786e\u4fdd\u5728\u8c03\u7528\u65f6\u4e0d\u4f1a\u4fdd\u7559\u9501\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"OffsetResetStrategy offsetResetStrategy = OffsetResetStrategy.valueOf(config.getString(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG).toUpperCase(Locale.ROOT));\nthis.subscriptions = new SubscriptionState(offsetResetStrategy);\nList<PartitionAssignor> assignors = config.getConfiguredInstances(\n        ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG,\n        PartitionAssignor.class);\nthis.coordinator = new ConsumerCoordinator(..............);\nthis.fetcher = new Fetcher<>(............................);\n")),(0,i.kt)("h3",{id:"offsetresetstrategy"},"OffsetResetStrategy"),(0,i.kt)("p",null,"\u679a\u4e3e\u7c7b LATEST, EARLIEST, NONE"),(0,i.kt)("h3",{id:"partitionassignor"},"PartitionAssignor"),(0,i.kt)("p",null,"this interface is used to define custom partition assignment for use in KafkaConsumer. Members of the consumer group subscribe to the topics they are interested in and forward their subscriptions to a Kafka broker serving as the group coordinator. The coordinator selects one member to perform the group assignment and propagates the subscriptions of all members to it. Then assign(Cluster, Map)} is called to perform the assignment and the results are forwarded back to each respective members",(0,i.kt)("br",{parentName:"p"}),"\n","In some cases, it is useful to forward additional metadata to the assignor in order to make assignment decisions. For this, you can override {@link #subscription(Set)} and provide custom userData in the returned Subscription. For example, to have a rack-aware assignor, an implementation can use this user data to forward the rackId belonging to each member.",(0,i.kt)("br",{parentName:"p"}),"\n","\u6d88\u8d39\u8005\u7684\u5206\u533a\u5206\u914d\u63a5\u53e3"),(0,i.kt)("h3",{id:"consumercoordinator"},"ConsumerCoordinator"),(0,i.kt)("p",null,"This class manages the coordination process with the consumer coordinator.",(0,i.kt)("br",{parentName:"p"}),"\n","\u6d88\u8d39\u8005\u534f\u8c03\u5458\u7ba1\u7406"),(0,i.kt)("h3",{id:"fetcher"},"Fetcher"),(0,i.kt)("p",null,"This class manage the fetching process with the brokers.",(0,i.kt)("br",{parentName:"p"}),"\n","\u7ba1\u7406\u4ece broker \u6293\u53d6\u6570\u636e"),(0,i.kt)("h2",{id:"subscribe"},"subscribe"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"public void subscribe(Collection<String> topics) {\n    subscribe(topics, new NoOpConsumerRebalanceListener());\n}\n")),(0,i.kt)("p",null,"Subscribe to the given list of topics to get dynamically assigned partitions. Topic subscriptions are not incremental. This list will replace the current assignment (if there is one). It is not possible to combine topic subscription with group management with manual partition assignment through assign(Collection).",(0,i.kt)("br",{parentName:"p"}),"\n","\u8ba2\u9605\u7ed9\u5b9a\u4e3b\u9898\u5217\u8868\uff0c\u5206\u533a\u52a8\u6001\u5206\u914d\u3002\u4e0e\u81ea\u5b9a\u4e49\u5206\u914d(assign())\u4e0d\u53ef\u540c\u65f6\u4f7f\u7528\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"public void subscribe(Collection<String> topics, ConsumerRebalanceListener listener) {\n.......................\n     this.subscriptions.subscribe(new HashSet<>(topics), listener);\n     metadata.setTopics(subscriptions.groupSubscription());\n.......................\n}\n")),(0,i.kt)("p",null,"As part of group management, the consumer will keep track of the list of consumers that belong to a particular group and will trigger a rebalance operation if one of the following events trigger",(0,i.kt)("br",{parentName:"p"}),"\n","\u65b0\u6d88\u8d39\u8005\u7684\u52a0\u5165\uff0c\u7ec4\u7ba1\u7406\u4e2d\u6d88\u8d39\u8005\u4f1a\u53ef\u80fd\u5c5e\u4e8e\u5df2\u7ecf\u5b58\u5728\u7684\u7ec4\uff0c\u6216\u8005\u65b0\u7ec4\u3002\u5982\u679c\u53d1\u751f\u4ee5\u4e0b\u4e8b\u4ef6\u5c06\u89e6\u53d1\u91cd\u65b0\u5e73\u8861\u64cd\u4f5c\uff1a"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Number of partitions change for any of the subscribed list of topics. \u5df2\u8ba2\u9605\u4e3b\u9898\u5217\u8868\u7684\u5206\u533a\u6539\u52a8"),(0,i.kt)("li",{parentName:"ul"},"Topic is created or deleted. \u4e3b\u9898\u521b\u5efa\u6216\u5220\u9664"),(0,i.kt)("li",{parentName:"ul"},"An existing member of the consumer group dies. \u7ec4\u4e2d\u6709\u6210\u5458\u79bb\u7ebf(\u6b7b\u4ea1)"),(0,i.kt)("li",{parentName:"ul"},"A new member is added to an existing consumer group via the join API. \u7ec4\u4e2d\u6709\u65b0\u6210\u5458\u52a0\u5165")),(0,i.kt)("p",null,"\u5f53\u89e6\u53d1\u4efb\u4f55\u8fd9\u4e9b\u4e8b\u4ef6\u65f6\uff0c\u5c06\u9996\u5148\u8c03\u7528\u63d0\u4f9b\u7684\u4fa6\u542c\u5668\u6765\u6307\u793a\u6d88\u8d39\u8005\u7684\u4f5c\u4e1a\u5df2\u88ab\u64a4\u9500\uff0c\u7136\u540e\u518d\u6b21\u63a5\u6536\u5230\u65b0\u7684\u4f5c\u4e1a\u3002"),(0,i.kt)("h2",{id:"consumer-poll"},"consumer poll"),(0,i.kt)("p",null,"\u5b9e\u73b0\u7c7b org.apache.kafka.clients.consumer. KafkaConsumer.java"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},'public ConsumerRecords<K, V> poll(long timeout) {\n    acquire();\n    try {\n        if (timeout < 0)\n            throw new IllegalArgumentException("Timeout must not be negative");\n\n        if (this.subscriptions.hasNoSubscriptionOrUserAssignment())\n            throw new IllegalStateException("Consumer is not subscribed to any topics or assigned any partitions");\n\n        // poll for new data until the timeout expires\n        long start = time.milliseconds();\n        long remaining = timeout;\n        do {\n         Map<TopicPartition, List<ConsumerRecord<K, V>>> records =pollOnce(remaining);\n            if (!records.isEmpty()) {\n                  if (fetcher.sendFetches() > 0 ||\n        client.hasPendingRequests()){client.pollNoWakeup();}\n.......}\n            long elapsed = time.milliseconds() - start;\n            remaining = timeout - elapsed;\n        } while (remaining > 0);\n        return ConsumerRecords.empty();\n} finally {\n        release();\n    }\n}\n')),(0,i.kt)("h3",{id:"acquire"},"acquire()"),(0,i.kt)("p",null,"\u5224\u65ad consumer \u662f\u5426\u591a\u7ebf\u7a0b\u8bbf\u95ee\uff0cconsumer \u975e\u7ebf\u7a0b\u5b89\u5168\uff0c\u5982\u679c\u591a\u7ebf\u7a0b\u4f7f\u7528\u4f1a\u62a5\u5f02\u5e38 ConcurrentModificationException"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"if(!records.isEmpty()){\n    if(fetcher.sendFetches()>0||client.hasPendingRequests()){\n        client.pollNoWakeup();\n    }\n    ........\n}\n")),(0,i.kt)("p",null,"before returning the fetched records, we can send off the next round of fetches and avoid block waiting for their responses to enable pipelining while the user is handling the fetched records.",(0,i.kt)("br",{parentName:"p"}),"\n","\u5728\u8fd4\u56de\u6293\u53d6\u7684\u6570\u636e\u65f6\uff0c\u53d1\u9001\u4e0b\u4e00\u8f6e\u63d0\u53d6\u8bf7\u6c42\u3002\u5373\uff0c\u7528\u6237\u5728\u63a5\u6536\u5230\u6570\u636e\u7684\u65f6\u5019\uff0c\u4e0b\u4e00\u6b21\u63d0\u53d6\u6570\u636e\u7684\u8bf7\u6c42\u5df2\u7ecf\u53d1\u51fa\u53bb\u4e86\u3002"),(0,i.kt)("h3",{id:"pollonce"},"pollOnce"),(0,i.kt)("p",null,"\u5b9e\u73b0\u7c7b org.apache.kafka.clients.consumer. KafkaConsumer.java",(0,i.kt)("br",{parentName:"p"}),"\n","Do one round of polling. In addition to checking for new data, this does any needed offset commits (if auto-commit is enabled), and offset resets (if an offset reset policy is defined).",(0,i.kt)("br",{parentName:"p"}),"\n","\u4e00\u6b21 poll\u3002\u9664\u4e86\u68c0\u67e5\u65b0\u6570\u636e\uff0c\u8fd8\u4f1a\u6d89\u53ca offset \u63d0\u4ea4\u4ee5\u53ca offset reset\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"private Map<TopicPartition, List<ConsumerRecord<K, V>>> pollOnce(long timeout) {\n    client.maybeTriggerWakeup();\n    coordinator.poll(time.milliseconds());\n    // fetch positions if we have partitions we're subscribed to that we\n    // don't know the offset for\n    if (!subscriptions.hasAllFetchPositions())\n        updateFetchPositions(this.subscriptions.missingFetchPositions());\n    // if data is available already, return it immediately\n   Map<TopicPartition, List<ConsumerRecord<K, V>>> records = fetcher.fetchedRecords();\n    if (!records.isEmpty())\n        return records;\n    // send any new fetches (won't resend pending fetches)\n    fetcher.sendFetches();\n    long now = time.milliseconds();\n    long pollTimeout = Math.min(coordinator.timeToNextPoll(now), timeout);\n    client.poll(pollTimeout, now, new PollCondition() {\n        @Override\n        public boolean shouldBlock() {\n       // since a fetch might be completed by the background thread, we need this poll condition to ensure that we do not block unnecessarily in poll()\n            return !fetcher.hasCompletedFetches();\n        }\n    });\n    // after the long poll, we should check whether the group needs to rebalance prior to returning data so that the group can stabilize faster\n    if (coordinator.needRejoin())\n        return Collections.emptyMap();\n    return fetcher.fetchedRecords();\n}\n")),(0,i.kt)("h3",{id:"clientmaybetriggerwakeup"},"client.maybeTriggerWakeup()"),(0,i.kt)("p",null,"\u54cd\u5e94\u7528\u6237\u7684 wakeup\uff0c\u629b\u51fa WakeupException\uff0c\u5982\u591a\u7ebf\u7a0b\u4f7f\u7528\u4e2d\u4ee5\u6b64\u6765\u505c\u6b62 consumer\u3002"),(0,i.kt)("h3",{id:"coordinatorpoll"},"coordinator.poll"),(0,i.kt)("p",null,"\u5b9e\u73b0\u7c7b org.apache.kafka.clients.consumer.internals. ConsumerCoordinator.java",(0,i.kt)("br",{parentName:"p"}),"\n","Poll for coordinator events. This ensures that the coordinator is known and that the consumer has joined the group (if it is using group management). This also handles periodic offset commits if they are enabled.",(0,i.kt)("br",{parentName:"p"}),"\n","coordinator \u7684 poll \u4e8b\u4ef6\uff0c\u5982\u4e0b\uff1a"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"public void poll(long now) {\n    invokeCompletedOffsetCommitCallbacks();\n    if (subscriptions.partitionsAutoAssigned() && coordinatorUnknown()) {\n        ensureCoordinatorReady();\n        now = time.milliseconds();\n    }\n    if (needRejoin()) {\n// due to a race condition between the initial metadata fetch and the initial rebalance, we need to ensure that the metadata is fresh before joining initially. This ensures that we have matched the pattern against the cluster's topics at least once before joining.\n        if (subscriptions.hasPatternSubscription())\n            client.ensureFreshMetadata();\n            ensureActiveGroup();\n            now = time.milliseconds();\n    }\n    pollHeartbeat(now);\n    maybeAutoCommitOffsetsAsync(now);\n}\n")),(0,i.kt)("h3",{id:"invokecompletedoffsetcommitcallbacks"},"invokeCompletedOffsetCommitCallbacks"),(0,i.kt)("p",null,"ConcurrentLinkedQueue\\<OffsetCommitCompletion",">","\uff1a\nthis collection must be thread-safe because it is modified from the response handler of offset commit requests, which may be invoked from the heartbeat thread.",(0,i.kt)("br",{parentName:"p"}),"\n","\u7ebf\u7a0b\u5b89\u5168\u7684\u96c6\u5408(\u961f\u5217)\uff0ccommit offset \u8bf7\u6c42\u54cd\u5e94\u903b\u8f91\u4e2d\u66f4\u6539\u6216\u8005\u5fc3\u8df3\u7ebf\u7a0b\u4e2d\u8c03\u7528\u3002offsetcommit \u7684 callback \u8fd4\u56de\u4e2d\u5904\u7406\u4e00\u4e9b\u903b\u8f91\uff0c\u5982\u679c\u5df2\u6d88\u8d39\u7684 offset \u8bb0\u5f55 server \u6ca1\u6709\u8868\u793a\uff0c\u5f97\u963b\u585e\u5904\u7406(invoke)\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"if (subscriptions.partitionsAutoAssigned() && coordinatorUnknown()) {\n        ensureCoordinatorReady();\n        now = time.milliseconds();\n    }\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"\u4fdd\u8bc1 coordinator \u5c31\u7eea(\u662f\u597d\u7684)\uff0c\u5426\u5219\u963b\u585e(ensureCoordinatorReady()\u963b\u585e\u5904\u7406\u903b\u8f91)")),(0,i.kt)("p",null,"Block until the coordinator for this group is known and is ready to receive requests."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"needRejoin()")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"if (!subscriptions.partitionsAutoAssigned())\n    return false;\n// we need to rejoin if we performed the assignment and metadata has changed\nif (assignmentSnapshot != null && !assignmentSnapshot.equals(metadataSnapshot))\n    return true;\n// we need to join if our subscription has changed since the last join\nif (joinedSubscription != null && !joinedSubscription.equals(subscriptions.subscription()))\n    return true;\nreturn super.needRejoin();\n")),(0,i.kt)("p",null,"\u5982\u679c\u8c03\u7528 subscribe \u63a5\u53e3\u6d88\u8d39\uff0c\u5219 partitionsAutoAssigned \u4e3a true\u3002",(0,i.kt)("br",{parentName:"p"}),"\n","\u5982\u679c\u4f7f\u7528\u6a21\u5f0f\u5339\u914d\u7684\u8bdd\uff0c\u5219\u8981 ensureFreshMetadata\uff1a\nEnsure our metadata is fresh (if an update is expected, this will block until it has completed)."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"ensureActiveGroup()")),(0,i.kt)("p",null,"Ensure that the group is active (i.e. joined and synced)"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"public void ensureActiveGroup() {\n// always ensure that the coordinator is ready because we may have been disconnected when sending heartbeats and does not necessarily require us to rejoin the group.\n    ensureCoordinatorReady();\n    startHeartbeatThreadIfNeeded();\n    joinGroupIfNeeded();\n}\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"ensureCoordinatorReady()")),(0,i.kt)("p",null,"ensureCoordinatorReady(): Block until the coordinator for this group is known and is ready to receive requests."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"pollHeartbeat(now)")),(0,i.kt)("p",null,"Check the status of the heartbeat thread (if it is active) and indicate the liveness of the client. This must be called periodically after joining with ensureActiveGroup() to ensure that the member stays in the group. If an interval of time longer than the provided rebalance timeout expires without calling this method, then the client will proactively leave the group.",(0,i.kt)("br",{parentName:"p"}),"\n","\u901a\u8fc7\u5fc3\u8df3\u5224\u65ad client \u662f\u5426\u5b58\u6d3b\uff0c\u5468\u671f\u6027\u7684\u53d1\u9001\u5fc3\u8df3\u5305\uff0c\u5982\u679c\u8d85\u65f6\u5219 client \u5c06\u88ab\u79fb\u51fa\u6240\u5728\u7ec4\u3002"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"maybeAutoCommitOffsetsAsync(now)")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"private void maybeAutoCommitOffsetsAsync(long now) {\n    if (autoCommitEnabled) {\n        if (coordinatorUnknown()) {\n            this.nextAutoCommitDeadline = now + retryBackoffMs;\n        } else if (now >= nextAutoCommitDeadline) {\n            this.nextAutoCommitDeadline = now + autoCommitIntervalMs;\n            doAutoCommitOffsetsAsync();\n        }\n    }\n}\n\nprivate void doAutoCommitOffsetsAsync() {\nMap<TopicPartition, OffsetAndMetadata> allConsumedOffsets = subscriptions.allConsumed();\n    commitOffsetsAsync(allConsumedOffsets, new OffsetCommitCallback() {......});\n}\n\npublic void commitOffsetsAsync(final Map<TopicPartition, OffsetAndMetadata> offsets, final OffsetCommitCallback callback) {\ninvokeCompletedOffsetCommitCallbacks();\nif (!coordinatorUnknown()) {\n   doCommitOffsetsAsync(offsets, callback);\n    } else {.......}\n\nprivate void doCommitOffsetsAsync(final Map<TopicPartition, OffsetAndMetadata> offsets, final OffsetCommitCallback callback) {\n    this.subscriptions.needRefreshCommits();\n    RequestFuture<Void> future = sendOffsetCommitRequest(offsets);\n...................\n    future.addListener(new RequestFutureListener<Void>() {\n..............\ncompletedOffsetCommits.add(new OffsetCommitCompletion(cb, offsets, null));\n..............\n}\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"sendOffsetCommitRequest(offsets)")),(0,i.kt)("p",null,"Commit offsets for the specified list of topics and partitions. This is a non-blocking call which returns a request future that can be polled in the case of a synchronous commit or ignored in the asynchronous case.",(0,i.kt)("br",{parentName:"p"}),"\n","\u63d0\u4ea4\u5177\u4f53\u7684 topic \u548c partition \u7684 offsets\uff0c\u975e\u963b\u585e\uff0c\u8fd4\u56de future."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"subscriptions.allConsumed()")),(0,i.kt)("p",null,"\u83b7\u53d6\u63d0\u4ea4\u7684 offset\uff0c\u5982\u4e0b\uff1a"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"public Map<TopicPartition, OffsetAndMetadata> allConsumed() {\n......................\nallConsumed.put(state.topicPartition(),newOffsetAndMetadata(state.value().position).............}\n//state.value().position\u5373\u4e0b\u9762\u7684position\uff0c\u6700\u540e\u6d88\u8d39\u7684\u4f4d\u7f6e\uff0c\u7531\u4e0b\u6587\u7684fetchPositions\u66f4\u65b0\n\nprivate static class TopicPartitionState {\n    private Long position; // last consumed position\n    private Long highWatermark; // the high watermark from last fetch\n    private OffsetAndMetadata committed;  // last committed position\n    private boolean paused;  // whether this partition has been paused by the user\n    private OffsetResetStrategy resetStrategy;  // the strategy to use if the offset needs resetting\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"updateFetchPositions()")),(0,i.kt)("p",null,"fetch positions if we have partitions we're subscribed to that we don't know the offset for",(0,i.kt)("br",{parentName:"p"}),"\n","\u5224\u65ad\u6240\u6709 partition \u7684 offset \u662f\u5426\u6709\u6548\uff0c\u5426\u5219\u66f4\u65b0\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"}," if (!subscriptions.hasAllFetchPositions())\n        updateFetchPositions\n\nprivate void updateFetchPositions(Set<TopicPartition> partitions) {\n    // lookup any positions for partitions which are awaiting reset\nfetcher.resetOffsetsIfNeeded(partitions);\n    if (!subscriptions.hasAllFetchPositions(partitions)) {\n// if we still don't have offsets for the given partitions, then we should either eek to the last committed position or reset using the auto reset policy\n    // first refresh commits for all assigned partitions\n      coordinator.refreshCommittedOffsetsIfNeeded();\n    // then do any offset lookups in case some positions are not known\n        fetcher.updateFetchPositions(partitions);\n    }\n}\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"fetchedRecords()")),(0,i.kt)("p",null,"Return the fetched records, empty the record buffer and update the consumed position.",(0,i.kt)("br",{parentName:"p"}),"\n","NOTE: returning empty records guarantees the consumed position are NOT updated.",(0,i.kt)("br",{parentName:"p"}),"\n","\u8fd4\u56de\u83b7\u53d6\u7684\u8bb0\u5f55\uff0c\u6e05\u7a7a\u8bb0\u5f55\u7f13\u51b2\u533a\u5e76\u66f4\u65b0\u6d88\u8d39\u7684\u4f4d\u7f6e(consumed position)",(0,i.kt)("br",{parentName:"p"}),"\n","\u6ce8\u610f\uff1a\u8fd4\u56de\u7a7a\u8bb0\u5f55\u4fdd\u8bc1\u6d88\u8d39\u7684\u4f4d\u7f6e\u4e0d\u66f4\u65b0"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"public Map<TopicPartition, List<ConsumerRecord<K, V>>> fetchedRecords() {\n  ..........\nwhile (recordsRemaining > 0) {\n      ................\nList<ConsumerRecord<K, V>> records=fetchRecords(nextInLineRecords,recordsRemaining);\nif (!records.isEmpty()) {\n      List<ConsumerRecord<K, V>> currentRecords = fetched.get(partition);\n          if (currentRecords == null) {\n                    fetched.put(partition, records);\n          } else {\n // this case shouldn't usually happen because we only send one fetch at a time per partition, but it might conceivably happen in some rare cases (such as partition leader changes). we have to copy to a new list because the old one may be immutable\nList<ConsumerRecord<K, V>> newRecords = new ArrayList<>(records.size() + currentRecords.size());\n                    newRecords.addAll(currentRecords);\n                    newRecords.addAll(records);\n                    fetched.put(partition, newRecords);\n                }\n                recordsRemaining -= records.size();\n            }\n        }\n    }\n\n    return fetched;\n}\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"fetchRecords(nextInLineRecords, recordsRemaining)")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"private List<ConsumerRecord<K, V>> fetchRecords(PartitionRecords partitionRecords, int maxRecords) {\n   ..................\n      long position = subscriptions.position(partitionRecords.partition);\n   ....................\n   if (partitionRecords.nextFetchOffset == position) {\nList<ConsumerRecord<K, V>> partRecords = partitionRecords.fetchRecords(maxRecords);\n  long nextOffset = partitionRecords.nextFetchOffset;\n  //\u66f4\u65b0consumed position\n  subscriptions.position(partitionRecords.partition, nextOffset);\n...........................\n}\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"client.poll(pollTimeout, now, new PollCondition()...)")),(0,i.kt)("p",null,"Do actual reads and writes from sockets."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"sendFetches()")),(0,i.kt)("p",null,"Set-up a fetch request for any node that we have assigned partitions for which doesn't already have an in-flight fetch or pending fetch data.",(0,i.kt)("br",{parentName:"p"}),"\n","\u53d1\u9001\u65b0\u7684\u6293\u53d6\u8bf7\u6c42(\u4e0d\u4f1a\u53d1\u9001\u7b49\u5f85\u5904\u7406\u7684\u8bf7\u6c42)\u3002\u5982\u672a\u53d1\u9001\u8fc7 fetch \u8bf7\u6c42\u7684\u5206\u533a\u8282\u70b9\u6216\u6302\u8d77\u6570\u636e\u7684\u5206\u533a\u8282\u70b9\u3002partition \u7684\u8bfb\u5199\u8bf7\u6c42\u843d\u4e8e leader, leader \u843d\u4e8e\u4e00\u53f0 broker\u3002\u4e00\u4e2a partition \u4e00\u4e2a fetch \u8bf7\u6c42\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"public int sendFetches() {\n    Map<Node, FetchRequest.Builder> fetchRequestMap = createFetchRequests();\n    for (Map.Entry<Node, FetchRequest.Builder> fetchEntry : fetchRequestMap.entrySet()) {\n        final FetchRequest.Builder request = fetchEntry.getValue();\n        final Node fetchTarget = fetchEntry.getKey();\n        client.send(fetchTarget, request)\n                .addListener(new RequestFutureListener<ClientResponse>() {......});\n}\n    return fetchRequestMap.size();\n}\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"createFetchRequests()")),(0,i.kt)("p",null,"Create fetch requests for all nodes for which we have assigned partitions that have no existing requests in flight.",(0,i.kt)("br",{parentName:"p"}),"\n","\u521b\u5efa fetch request"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"private Map<Node, FetchRequest.Builder> createFetchRequests() {\n    // create the fetch info\n   .............\nfor (TopicPartition partition : fetchablePartitions()) {\n.............\nLinkedHashMap<TopicPartition, FetchRequest.PartitionData> fetch.......\nfetchable.put(node, fetch);\n.............\nlong position = this.subscriptions.position(partition);\n//fetch\u4e2d\u653e\u5165\u6b64partition\u7684last consumed position\nfetch.put(partition, new FetchRequest.PartitionData(position, FetchRequest.INVALID_LOG_START_OFFSET, this.fetchSize));\n................\n}\n// create the fetches\nMap<Node, FetchRequest.Builder> requests = new HashMap<>();\nfor (Map.Entry<Node, LinkedHashMap<TopicPartition, FetchRequest.PartitionData>> entry : fetchable.entrySet()) {\nNode node = entry.getKey();\nFetchRequest.Builder fetch = FetchRequest.Builder.forConsumer(this.maxWaitMs, this.minBytes, entry.getValue()).setMaxBytes(this.maxBytes);\n        requests.put(node, fetch);\n}\nreturn requests;}\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"forConsumer(this.maxWaitMs...)")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"public static Builder forConsumer(int maxWait, int minBytes, LinkedHashMap<TopicPartition, PartitionData> fetchData) {\n    return new Builder(null, CONSUMER_REPLICA_ID, maxWait, minBytes, fetchData);\n}\n")))}d.isMDXComponent=!0}}]);